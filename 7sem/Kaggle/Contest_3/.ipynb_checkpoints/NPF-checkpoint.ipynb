{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from random import shuffle\n",
    "from sklearn import tree\n",
    "from copy import deepcopy\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn import cross_validation\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from scipy.optimize import minimize_scalar\n",
    "from sklearn import preprocessing\n",
    "import math\n",
    "import xgboost as xgb\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вспомогательные функции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def smape_loss_func(x, y):\n",
    "    SymAPE = [ 2*np.abs(x-y)/(np.abs(x)+np.abs(y))] \n",
    "    return np.mean(SymAPE)\n",
    "\n",
    "def get_numerated_data(df, categorical_columns):\n",
    "    simple_df = deepcopy(df)\n",
    "    for column in categorical_columns:\n",
    "        simple_df[column] = pd.Categorical.from_array(simple_df[column]).labels\n",
    "    \n",
    "    return simple_df\n",
    "\n",
    "def get_binarized_data(df, categorical_columns):\n",
    "    binary_df = deepcopy(df)\n",
    "    for column in categorical_columns:\n",
    "        binary_df = pd.concat([binary_df, pd.get_dummies(binary_df[column], prefix=column, prefix_sep=': ')], axis=1)\n",
    "        del binary_df[column]\n",
    "    \n",
    "    return binary_df\n",
    "\n",
    "def split_to_numpy(df, y_column_name):\n",
    "    #print df\n",
    "    #print y_column_name\n",
    "    data_x = df.drop(y_column_name, axis=1).values.astype(np.float32)\n",
    "    data_y = df[y_column_name].values.astype(np.float32)\n",
    "    column_names = df.drop(y_column_name, axis=1).columns\n",
    "    \n",
    "    return data_x, data_y, column_names\n",
    "\n",
    "def split_train_test(df, test_size=0.5, random_state=42, y_column_name='y'):\n",
    "    X = np.asarray(df.drop(y_column_name, axis=1))\n",
    "    y = np.asarray(df[y_column_name]).ravel()\n",
    "    trainX, testX, trainY, testY = cross_validation.train_test_split(X, y, test_size=test_size, random_state=42)\n",
    "    return trainX, testX, trainY, testY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Другие модели и генерация дополнительных признаков (2 балла)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_results(reg, acc=smape_loss_func, min_max_filter=True, max_val=1, min_val=0.0001):\n",
    "    reg.fit(trainX, trainY)\n",
    "    predict = reg.predict(testX)\n",
    "    if min_max_filter:\n",
    "        predict = np.minimum(np.maximum(predict, min_val),max_val)\n",
    "    results = (acc(trainY, reg.predict(trainX)), acc(testY, predict))\n",
    "    print(\"Loss: \" + str(results[1]))    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def prepare_data(data, scalers=None):\n",
    "    Redundant_columns = ['MODEL_NAME', 'MODEL_COUNT_SALES_DAYS', 'MODEL_DIAG_TYPE','MODEL_HEIGHT', 'MODEL_WIDTH', 'STORE_OPEN_DTTM',\n",
    "                        'MODEL_BRAND', 'MODEL_OS', 'MODEL_TYPE']\n",
    "    data.drop(Redundant_columns, inplace=True, axis=1)\n",
    "    \n",
    "    for col in ['STORE_BRAND_ABC', 'STORE_DIAG_ABC', 'STORE_RES_ABC']:\n",
    "        data[col].fillna('C', inplace=True)\n",
    "        data[col] = data[col].apply(lambda x: ord('C') - ord(x))\n",
    "    bad_cat_columns = ['MODEL_ID']\n",
    "    data.drop(bad_cat_columns, axis=1, inplace=True)\n",
    "    Categorical_columns = data.columns[([isinstance(z, str) for z in data.ix[0]])]\n",
    "    for col in Categorical_columns:\n",
    "        data = get_binarized_data(data, [col])\n",
    "    data['MODEL_MEAN_SALES'].fillna(-100, inplace=True)\n",
    "    data.fillna(data.mean(), inplace=True)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_data = prepare_data(pd.read_csv('train.csv', sep=';', index_col='ID'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40000, 116)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_data = prepare_data(pd.read_csv('test.csv', sep=';', index_col='ID'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11296, 115)\n"
     ]
    }
   ],
   "source": [
    "print test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainX, testX, trainY, testY = split_train_test(df = train_data, test_size=0.15,  y_column_name='DEMAND')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testX = test.drop(['DEMAND'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainY = train_data['DEMAND']\n",
    "trainX = train_data.drop(['DEMAND'], axis=1)\n",
    "model = tree.DecisionTreeRegressor().fit(trainX, trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred = pd.DataFrame(model.predict(test_data), index = test_data.index, columns=pd.Index(['DEMAND']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred.to_csv('submission3.csv', sep = ',', index = True)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
