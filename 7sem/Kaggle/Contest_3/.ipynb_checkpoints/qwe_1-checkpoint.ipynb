{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from random import shuffle\n",
    "from sklearn import tree\n",
    "from copy import deepcopy\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import cross_validation\n",
    "from scipy.optimize import minimize_scalar\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def smape_loss_func(x, y):\n",
    "    SymAPE = [ 2*np.abs(x-y)/(np.abs(x)+np.abs(y))] \n",
    "    return np.mean(SymAPE)\n",
    "\n",
    "def get_binarized_data(df, categorical_columns):\n",
    "    binary_df = deepcopy(df)\n",
    "    for column in categorical_columns:\n",
    "        binary_df = pd.concat([binary_df, pd.get_dummies(binary_df[column], prefix=column, prefix_sep=': ')], axis=1)\n",
    "        del binary_df[column]\n",
    "    \n",
    "    return binary_df\n",
    "\n",
    "def split_train_test(df, test_size=0.5, random_state=42, y_column_name='y'):\n",
    "    X = np.asarray(df.drop(y_column_name, axis=1))\n",
    "    y = np.asarray(df[y_column_name]).ravel()\n",
    "    trainX, testX, trainY, testY = cross_validation.train_test_split(X, y, test_size=test_size, random_state=42)\n",
    "    return trainX, testX, trainY, testY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучение и Контроль"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv', sep=';',decimal= '.', index_col='ID')\n",
    "test = pd.read_csv('test.csv', sep=';',decimal= '.', index_col='ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def apply_f_to_col_inline(df, col, f):\n",
    "    df[col] = df[col].apply(f)\n",
    "    \n",
    "def get_mean_demand_for_value(df, column, value):\n",
    "    interested_in = df[['DEMAND', column]]\n",
    "    interested_in = interested_in.loc[df[column] == value]\n",
    "    mean = interested_in.mean()[0]\n",
    "    return 0 if np.isnan(mean) else mean\n",
    "\n",
    "def process_bad_categorical_columns(df, columns, mean_demands):\n",
    "    for column in columns:\n",
    "        values = set(df[column].values)\n",
    "        apply_f_to_col_inline(df, column,lambda x :\n",
    "                              0 if x not in mean_demands[column].keys() else mean_demands[column][x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def collect_mean_demands(data):\n",
    "    data = train\n",
    "    Categorical_columns = data.columns[([isinstance(z, str) for z in data.ix[0]])].append([['LOCATION_ID', 'MODEL_ID']])\n",
    "    dist_val = pd.DataFrame({'NoUniqueValues': [data[z].nunique() for z in Categorical_columns]}, index = Categorical_columns)\n",
    "    threshold = 7\n",
    "    bad_cat_columns = dist_val.ix[dist_val['NoUniqueValues']>threshold].axes[0]\n",
    "    mean_demands = dict()\n",
    "    for column in bad_cat_columns:\n",
    "        values = set(data[column].values)\n",
    "        mean_demands[column] = dict()\n",
    "        for value in values:\n",
    "            mean_demands[column][value] = get_mean_demand_for_value(data, column, value)\n",
    "    return mean_demands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_predict(train_data, test_data):\n",
    "    cat_columns = train_data.columns[([isinstance(z, str) for z in train_data.ix[0]])]\n",
    "    bad_cat_columns = ['MODEL_OS', 'STORE_PRICE_TYPE', 'STORE_CLUSTER', 'STORE_REGION',\n",
    "                       'MODEL_NAME', 'MODEL_DIAG_TYPE', 'MODEL_HEIGHT', 'MODEL_WIDTH', 'MODEL_TYPE', 'STORE_OPEN_DTTM',\n",
    "                       'STORE_BUILDING_TYPE', 'STORE_CITY', 'MODEL_RES_TYPE', \n",
    "                       'STORE_BRAND_ABC', 'STORE_FORMAT']\n",
    "    bad_cat_columns = []\n",
    "    bad_num_columns = ['STORE_ASSORTMENT', 'STORE_RES_SPECTR', 'STORE_BRAND_SPECTR', 'STORE_DIAG_SPECTR',\n",
    "                       'MODEL_COUNT_SALES_DAYS']\n",
    "    bad_num_columns = []\n",
    "    #for col in ['STORE_BRAND_ABC', 'STORE_DIAG_ABC', 'STORE_RES_ABC']:\n",
    "    #    train_data[col].fillna('C', inplace=True)\n",
    "    #    train_data[col] = train_data[col].apply(lambda x: ord('C') - ord(x))\n",
    "    #    test_data[col].fillna('C', inplace=True)\n",
    "    #    test_data[col] = test_data[col].apply(lambda x: ord('C') - ord(x))\n",
    "    \n",
    "    good_cat_columns = [cat_columns[i] for i in range(len(cat_columns)) if cat_columns[i] not in bad_cat_columns]\n",
    "    train_data.drop(bad_cat_columns, axis = 1, inplace=True)\n",
    "    train_data.drop(bad_num_columns, axis = 1, inplace=True)\n",
    "    \n",
    "    #mean_demands = collect_mean_demands(train_data)\n",
    "    #to_process = ['MODEL_ID']\n",
    "    #process_bad_categorical_columns(train_data, to_process, mean_demands)\n",
    "    #process_bad_categorical_columns(test_data, to_process, mean_demands)\n",
    "    \n",
    "    train_data.fillna(-100, inplace=True)\n",
    "    bin_train_data = get_binarized_data(train_data, good_cat_columns)\n",
    "    print ('bin_train:', bin_train_data.shape)\n",
    "    test_data.drop(bad_cat_columns, axis = 1, inplace=True)\n",
    "    test_data.drop(bad_num_columns, axis = 1, inplace=True)\n",
    "    test_data.fillna(-100, inplace=True)\n",
    "    bin_test_data = get_binarized_data(test_data, good_cat_columns)\n",
    "    print ('bin_test:', bin_test_data.shape)\n",
    "    # Все отсутствующие в тестовой выборке столбцы полагаем 0\n",
    "    add_columns = bin_train_data.columns[1:].difference(bin_test_data.columns)\n",
    "    bin_test_data = pd.merge(bin_test_data, bin_train_data.ix[bin_test_data.index][add_columns],\n",
    "                             how='inner', left_index=True, right_index=True)\n",
    "    bin_test_data[add_columns] = 0\n",
    "    # Оставляем только столбцы обучающей выборки (целевая переменная в обучающей выборке отсутствует)\n",
    "    bin_test_data = bin_test_data[bin_train_data.columns[1:]]\n",
    "    bin_test_data.fillna(-10, inplace=True)\n",
    "    print ('bin_test:', bin_test_data.shape)\n",
    "    # Обучающая выборка\n",
    "    trainX, _, trainY, _ = split_train_test(df=bin_train_data, test_size=0,  y_column_name='DEMAND')\n",
    "    #reg = tree.DecisionTreeRegressor().fit(trainX, trainY)\n",
    "    reg = BaggingRegressor(n_estimators=1,\n",
    "                          max_samples=0.9, max_features=0.9, random_state=1234, verbose=0).fit(trainX, trainY)\n",
    "    prediction = reg.predict(np.asarray(bin_test_data))\n",
    "    prediction = np.minimum(np.maximum(prediction, 0.0001), 1)\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Исключаем лишние произнаки, заменяем NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tatiana/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/tatiana/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/tatiana/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    train = pd.read_csv('train.csv', sep=';',decimal= '.', index_col='ID')\n",
    "    test = pd.read_csv('test.csv', sep=';',decimal= '.', index_col='ID')\n",
    "    msk = np.random.rand(len(train)) < 0.8\n",
    "    msk[0] = True\n",
    "    tr = train.iloc[msk]\n",
    "    te = train.iloc[~msk]\n",
    "    y = te['DEMAND'].values.ravel()\n",
    "    te.drop(['DEMAND'], axis=1, inplace=True)\n",
    "    test_predict = get_predict(tr, te)\n",
    "    test_predict = test_predict\n",
    "    print (smape_loss_func(y, test_predict))\n",
    "\n",
    "# Сохраняем в csv-файл\n",
    "#test_predict = get_predict(train, test)\n",
    "#test['DEMAND'] = test_predict\n",
    "#test[['DEMAND']].to_csv('.submission0.csv', sep = ',', index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.734641272794\n"
     ]
    }
   ],
   "source": [
    "print smape_loss_func(y, test_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bin_train: (40000, 867)\n",
      "bin_test: (11296, 782)\n",
      "bin_test: (11296, 866)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('train.csv', sep=';',decimal= '.', index_col='ID')\n",
    "test = pd.read_csv('test.csv', sep=';',decimal= '.', index_col='ID')\n",
    "test_predict = get_predict(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Сохраняем в csv-файл\n",
    "test['DEMAND'] = test_predict\n",
    "test[['DEMAND']].to_csv('submission0.csv', sep = ',', index = True)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
