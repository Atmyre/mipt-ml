
[+] General Parameters:
Training data:	./data/train.txt
Test data:	./data/test.txt
Validation data:	./data/valid.txt
Feature vector representation: Dense.
Ranking method:	MART
Feature description file:	Unspecified. All features will be used.
Train metric:	NDCG@10
Test metric:	NDCG@10
Feature normalization: No
Model file: ./model/MART_100_5.txt

[+] MART's Parameters:
No. of trees: 100
No. of leaves: 5
No. of threshold candidates: 256
Learning rate: 0.1
Stop early: 100 rounds without performance gain on validation data

Reading feature file [./data/train.txt]: 0... Reading feature file [./data/train.txt]... [Done.]            
(938 ranked lists, 9847 entries read)
Reading feature file [./data/valid.txt]: 0... Reading feature file [./data/valid.txt]... [Done.]            
(964 ranked lists, 9726 entries read)
Reading feature file [./data/test.txt]: 0... Reading feature file [./data/test.txt]... [Done.]            
(937 ranked lists, 9619 entries read)
Initializing... [Done]
---------------------------------
Training starts...
---------------------------------
#iter   | NDCG@10-T | NDCG@10-V | 
---------------------------------
1       | 0.6498    | 0.6836    | 
2       | 0.651     | 0.6903    | 
3       | 0.6592    | 0.6929    | 
4       | 0.6615    | 0.6951    | 
5       | 0.6629    | 0.6966    | 
6       | 0.6745    | 0.7018    | 
7       | 0.6761    | 0.7064    | 
8       | 0.6768    | 0.7074    | 
9       | 0.6771    | 0.7072    | 
10      | 0.6799    | 0.7083    | 
11      | 0.6792    | 0.7102    | 
12      | 0.6804    | 0.7095    | 
13      | 0.6842    | 0.7117    | 
14      | 0.6854    | 0.7132    | 
15      | 0.6886    | 0.7143    | 
16      | 0.6902    | 0.7149    | 
17      | 0.6909    | 0.718     | 
18      | 0.6909    | 0.7185    | 
19      | 0.6921    | 0.7173    | 
20      | 0.6929    | 0.7187    | 
21      | 0.6966    | 0.7187    | 
22      | 0.6979    | 0.7194    | 
23      | 0.6986    | 0.7205    | 
24      | 0.7007    | 0.721     | 
25      | 0.7031    | 0.7205    | 
26      | 0.7041    | 0.7211    | 
27      | 0.7056    | 0.7226    | 
28      | 0.7062    | 0.7226    | 
29      | 0.7067    | 0.7227    | 
30      | 0.7076    | 0.7225    | 
31      | 0.708     | 0.7222    | 
32      | 0.7104    | 0.7242    | 
33      | 0.7107    | 0.7244    | 
34      | 0.7104    | 0.7251    | 
35      | 0.712     | 0.7252    | 
36      | 0.7119    | 0.7247    | 
37      | 0.7131    | 0.7264    | 
38      | 0.7142    | 0.7265    | 
39      | 0.7141    | 0.7267    | 
40      | 0.714     | 0.7273    | 
41      | 0.714     | 0.7279    | 
42      | 0.7144    | 0.7282    | 
43      | 0.7145    | 0.7282    | 
44      | 0.7142    | 0.7273    | 
45      | 0.714     | 0.7267    | 
46      | 0.7141    | 0.7268    | 
47      | 0.7143    | 0.7263    | 
48      | 0.7142    | 0.7268    | 
49      | 0.7142    | 0.7272    | 
50      | 0.7148    | 0.7285    | 
51      | 0.7158    | 0.7287    | 
52      | 0.7155    | 0.729     | 
53      | 0.7164    | 0.7287    | 
54      | 0.7169    | 0.7284    | 
55      | 0.7181    | 0.7283    | 
56      | 0.7175    | 0.7284    | 
57      | 0.7178    | 0.7282    | 
58      | 0.7184    | 0.7283    | 
59      | 0.7187    | 0.7285    | 
60      | 0.7185    | 0.7282    | 
61      | 0.7198    | 0.7283    | 
62      | 0.7199    | 0.729     | 
63      | 0.7196    | 0.7288    | 
64      | 0.72      | 0.7289    | 
65      | 0.7199    | 0.7293    | 
66      | 0.721     | 0.7292    | 
67      | 0.722     | 0.7294    | 
68      | 0.723     | 0.7292    | 
69      | 0.7228    | 0.7285    | 
70      | 0.7243    | 0.7286    | 
71      | 0.7243    | 0.7288    | 
72      | 0.7251    | 0.7294    | 
73      | 0.7252    | 0.7282    | 
74      | 0.7254    | 0.7282    | 
75      | 0.7246    | 0.7283    | 
76      | 0.7242    | 0.7273    | 
77      | 0.7236    | 0.7281    | 
78      | 0.7246    | 0.7266    | 
79      | 0.7246    | 0.7265    | 
80      | 0.7256    | 0.7278    | 
81      | 0.7252    | 0.7281    | 
82      | 0.7257    | 0.728     | 
83      | 0.7258    | 0.7282    | 
84      | 0.7261    | 0.7282    | 
85      | 0.7262    | 0.7284    | 
86      | 0.7275    | 0.7277    | 
87      | 0.7275    | 0.7284    | 
88      | 0.7277    | 0.7284    | 
89      | 0.7275    | 0.7281    | 
90      | 0.7271    | 0.7281    | 
91      | 0.7272    | 0.7275    | 
92      | 0.7282    | 0.7271    | 
93      | 0.7282    | 0.7275    | 
94      | 0.7282    | 0.7271    | 
95      | 0.7272    | 0.727     | 
96      | 0.7274    | 0.7276    | 
97      | 0.7273    | 0.727     | 
98      | 0.7279    | 0.7272    | 
99      | 0.7293    | 0.7261    | 
100     | 0.7292    | 0.7265    | 
---------------------------------
Finished sucessfully.
NDCG@10 on training data: 0.7251
NDCG@10 on validation data: 0.7294
---------------------------------
NDCG@10 on test data: 0.7043

Model saved to: ./model/MART_100_5.txt
